"""
é›¶å”®åº«å­˜èª¿è²¨å»ºè­°ç”Ÿæˆç³»çµ±
Retail Inventory Transfer Suggestion System

ç‰ˆæœ¬: v1.0
é–‹ç™¼è€…: Ricky
æ›´æ–°æ—¥æœŸ: 2025-10-08

åŠŸèƒ½æ¦‚è¿°:
- æ”¯æ´ä¸‰ç¨®è½‰è²¨æ¨¡å¼ï¼šä¿å®ˆè½‰è²¨ã€åŠ å¼·è½‰è²¨ã€ç‰¹å¼·è½‰è²¨
- æ™ºæ…§è½‰è²¨å»ºè­°ç”Ÿæˆï¼ŒåŸºæ–¼åº«å­˜ç‹€æ³å’ŒéŠ·å”®æ•¸æ“š
- å®Œæ•´çš„çµ±è¨ˆåˆ†æå’Œè¦–è¦ºåŒ–å±•ç¤º
- ExcelåŒ¯å‡ºåŠŸèƒ½ï¼Œæ”¯æ´ä¼æ¥­æ‡‰ç”¨

æŠ€è¡“æ£§:
- å‰ç«¯ï¼šStreamlit
- è³‡æ–™è™•ç†ï¼špandas, numpy
- è¦–è¦ºåŒ–ï¼šmatplotlib, seaborn
- Excelè™•ç†ï¼šopenpyxl
"""

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import io
import xlsxwriter
import warnings
import logging

# è¨­å®šè­¦å‘Šå’Œæ—¥èªŒ
warnings.filterwarnings('ignore')

# è¨­å®šé é¢é…ç½®
st.set_page_config(
   page_title="èª¿è²¨å»ºè­°ç”Ÿæˆç³»çµ±",
   page_icon="ğŸ“¦",
   layout="wide",
   initial_sidebar_state="expanded"
)

# å®šç¾©å¿…è¦æ¬„ä½
REQUIRED_COLUMNS = [
   'Article', 'Article Description', 'RP Type', 'Site', 'OM', 'MOQ',
   'SaSa Net Stock', 'Target', 'Pending Received', 'Safety Stock',
   'Last Month Sold Qty', 'MTD Sold Qty'
]

# ============================================================================
# è³‡æ–™é©—è­‰èˆ‡é è™•ç†å‡½æ•¸
# ============================================================================

def validate_file_structure(df: pd.DataFrame) -> tuple[bool, str]:
   """
   é©—è­‰ä¸Šå‚³æª”æ¡ˆæ˜¯å¦åŒ…å«æ‰€æœ‰å¿…è¦æ¬„ä½

   Args:
       df: è¼¸å…¥çš„è³‡æ–™æ¡†

   Returns:
       tuple: (æ˜¯å¦æœ‰æ•ˆ, è¨Šæ¯)
   """
   missing_columns = [col for col in REQUIRED_COLUMNS if col not in df.columns]
   if missing_columns:
       return False, f"ç¼ºå°‘å¿…è¦æ¬„ä½: {', '.join(missing_columns)}"
   return True, "æª”æ¡ˆçµæ§‹é©—è­‰é€šé"

def preprocess_data(df: pd.DataFrame) -> pd.DataFrame:
   """
   æ ¹æ“šæ¥­å‹™è¦å‰‡é è™•ç†è³‡æ–™

   Args:
       df: åŸå§‹è³‡æ–™æ¡†

   Returns:
       pd.DataFrame: è™•ç†å¾Œçš„è³‡æ–™æ¡†
   """
   # å‰µå»ºå‰¯æœ¬é¿å…ä¿®æ”¹åŸè³‡æ–™
   processed_df = df.copy()

   # åˆå§‹åŒ–Notesæ¬„ä½ç”¨æ–¼è¨˜éŒ„è³‡æ–™æ¸…ç†æ—¥èªŒ
   processed_df['Notes'] = ''

   # 1. Articleæ¬„ä½å¼·åˆ¶è½‰æ›ç‚ºå­—ä¸²é¡å‹
   processed_df['Article'] = processed_df['Article'].astype(str)

   # 2. æ‰€æœ‰æ•¸é‡æ¬„ä½è½‰æ›ç‚ºæ•´æ•¸ï¼Œç„¡æ•ˆå€¼å¡«å……ç‚º0
   numeric_columns = [
       'MOQ', 'SaSa Net Stock', 'Target', 'Pending Received',
       'Safety Stock', 'Last Month Sold Qty', 'MTD Sold Qty'
   ]

   for col in numeric_columns:
       # è½‰æ›ç‚ºæ•¸å€¼ï¼ŒéŒ¯èª¤å€¼è¨­ç‚ºNaNï¼Œç„¶å¾Œå¡«å……ç‚º0ï¼Œæœ€å¾Œè½‰æ›ç‚ºæ•´æ•¸
       processed_df[col] = pd.to_numeric(processed_df[col], errors='coerce').fillna(0).astype(int)

   # 3. è² å€¼åº«å­˜å’ŒéŠ·é‡è‡ªå‹•ä¿®æ­£ç‚º0
   processed_df['SaSa Net Stock'] = processed_df['SaSa Net Stock'].clip(lower=0)
   processed_df['Last Month Sold Qty'] = processed_df['Last Month Sold Qty'].clip(lower=0)
   processed_df['MTD Sold Qty'] = processed_df['MTD Sold Qty'].clip(lower=0)

   # 4. éŠ·é‡ç•°å¸¸å€¼ï¼ˆ>100000ï¼‰é™åˆ¶ç‚º100000ä¸¦æ·»åŠ å‚™è¨»
   sales_outlier_mask = (processed_df['Last Month Sold Qty'] > 100000) | (processed_df['MTD Sold Qty'] > 100000)
   processed_df.loc[sales_outlier_mask, 'Notes'] = 'éŠ·é‡ç•°å¸¸å€¼å·²é™åˆ¶ç‚º100000'
   processed_df['Last Month Sold Qty'] = processed_df['Last Month Sold Qty'].clip(upper=100000)
   processed_df['MTD Sold Qty'] = processed_df['MTD Sold Qty'].clip(upper=100000)

   # 5. å­—ä¸²æ¬„ä½ç©ºå€¼å¡«å……ç‚ºç©ºå­—ä¸²
   string_columns = ['Article Description', 'RP Type', 'Site', 'OM']
   for col in string_columns:
       processed_df[col] = processed_df[col].fillna('').astype(str)

   # 6. é©—è­‰RP Typeæ¬„ä½å€¼ï¼ˆåªèƒ½æ˜¯NDæˆ–RFï¼‰
   invalid_rp_mask = ~processed_df['RP Type'].isin(['ND', 'RF'])
   processed_df.loc[invalid_rp_mask, 'Notes'] += ' RP Typeç„¡æ•ˆï¼Œå·²è¨­ç‚ºND'
   processed_df.loc[invalid_rp_mask, 'RP Type'] = 'ND'

   return processed_df

def calculate_effective_sales(row: pd.Series) -> int:
   """
   æ ¹æ“šæ¥­å‹™è¦å‰‡è¨ˆç®—æœ‰æ•ˆéŠ·é‡

   Args:
       row: è³‡æ–™è¡Œ

   Returns:
       int: æœ‰æ•ˆéŠ·é‡
   """
   if row['Last Month Sold Qty'] > 0:
       return row['Last Month Sold Qty']
   else:
       return row['MTD Sold Qty']

# ============================================================================
# è½‰è²¨å€™é¸è­˜åˆ¥å‡½æ•¸
# ============================================================================

def identify_transfer_out_candidates(df: pd.DataFrame, mode: str = 'conservative') -> pd.DataFrame:
   """
   æ ¹æ“šé¸æ“‡çš„æ¨¡å¼è­˜åˆ¥è½‰å‡ºå€™é¸

   Args:
       df: è™•ç†å¾Œçš„è³‡æ–™æ¡†
       mode: è½‰è²¨æ¨¡å¼ ('conservative', 'enhanced', 'special')

   Returns:
       pd.DataFrame: è½‰å‡ºå€™é¸æ¸…å–®
   """
   transfer_out_candidates = []

   # é¦–å…ˆè¨ˆç®—æ¯å€‹ç”¢å“åœ¨æ‰€æœ‰OMä¸­çš„ç¸½éœ€æ±‚
   total_demand_by_article = df[df['Target'] > 0].groupby('Article')['Target'].sum()

   # æŒ‰ç”¢å“å’ŒOMåˆ†çµ„è™•ç†
   grouped = df.groupby(['Article', 'OM'])

   for (article, om), group in grouped:
       # ç‚ºæ¯å€‹åº—é‹ªè¨ˆç®—æœ‰æ•ˆéŠ·é‡
       group['Effective Sales'] = group.apply(calculate_effective_sales, axis=1)

       # è¨ˆç®—æ­¤ç”¢å“åœ¨æ­¤OMä¸­çš„æœ€é«˜éŠ·é‡
       max_sales = group['Effective Sales'].max()

       # ç²å–æ­¤ç”¢å“åœ¨æ‰€æœ‰OMä¸­çš„ç¸½éœ€æ±‚
       article_total_demand = total_demand_by_article.get(article, 0)

       # å„ªå…ˆé †åº1ï¼šNDé¡å‹ç”¢å“å®Œå…¨è½‰å‡º
       nd_stores = group[group['RP Type'] == 'ND']
       for _, store in nd_stores.iterrows():
           if store['SaSa Net Stock'] > 0:
               transfer_out_candidates.append({
                   'Article': article,
                   'OM': om,
                   'Site': store['Site'],
                   'Transfer Type': 'NDè½‰å‡º',
                   'Available Stock': store['SaSa Net Stock'],
                   'Transfer Qty': store['SaSa Net Stock'],
                   'Effective Sales': store['Effective Sales'],
                   'Original Stock': store['SaSa Net Stock'],
                   'Safety Stock': store['Safety Stock'],
                   'MOQ': store['MOQ'],
                   'Pending Received': store['Pending Received'],
                   'Article Total Demand': article_total_demand
               })

       # å„ªå…ˆé †åº2ï¼šRFé¡å‹ç”¢å“è½‰å‡ºï¼ˆä¸åŒæ¨¡å¼ä¸åŒé‚è¼¯ï¼‰
       rf_stores = group[group['RP Type'] == 'RF']

       # æŒ‰æœ‰æ•ˆéŠ·é‡æ’åºï¼ˆæœ€ä½çš„å„ªå…ˆè½‰å‡ºï¼‰
       rf_stores_sorted = rf_stores.sort_values('Effective Sales', ascending=True)

       for _, store in rf_stores_sorted.iterrows():
           total_available = store['SaSa Net Stock'] + store['Pending Received']

           if mode == 'conservative':
               # ä¿å®ˆè½‰è²¨æ¨¡å¼
               if total_available > store['Safety Stock']:
                   base_transferable = total_available - store['Safety Stock']
                   max_transferable = int(total_available * 0.5)  # 50%é™åˆ¶
                   actual_transfer = min(base_transferable, max_transferable, store['SaSa Net Stock'])

                   if actual_transfer > 0:
                       transfer_out_candidates.append({
                           'Article': article,
                           'OM': om,
                           'Site': store['Site'],
                           'Transfer Type': 'RFéå‰©è½‰å‡º',
                           'Available Stock': store['SaSa Net Stock'],
                           'Transfer Qty': actual_transfer,
                           'Effective Sales': store['Effective Sales'],
                           'Original Stock': store['SaSa Net Stock'],
                           'Safety Stock': store['Safety Stock'],
                           'MOQ': store['MOQ'],
                           'Pending Received': store['Pending Received'],
                           'Article Total Demand': article_total_demand
                       })

           elif mode == 'enhanced':
               # åŠ å¼·è½‰è²¨æ¨¡å¼
               if total_available > (store['MOQ'] + 1):
                   base_transferable = total_available - (store['MOQ'] + 1)
                   max_transferable = int(total_available * 0.8)  # 80%é™åˆ¶
                   actual_transfer = min(base_transferable, max_transferable, store['SaSa Net Stock'])

                   if actual_transfer > 0:
                       transfer_out_candidates.append({
                           'Article': article,
                           'OM': om,
                           'Site': store['Site'],
                           'Transfer Type': 'RFåŠ å¼·è½‰å‡º',
                           'Available Stock': store['SaSa Net Stock'],
                           'Transfer Qty': actual_transfer,
                           'Effective Sales': store['Effective Sales'],
                           'Original Stock': store['SaSa Net Stock'],
                           'Safety Stock': store['Safety Stock'],
                           'MOQ': store['MOQ'],
                           'Pending Received': store['Pending Received'],
                           'Article Total Demand': article_total_demand
                       })

           else:  # special enhanced mode
               # ç‰¹å¼·è½‰è²¨æ¨¡å¼
               if total_available > 0 and store['Effective Sales'] < max_sales:
                   # åŸºç¤å¯è½‰å‡º = åº«å­˜ - 2ä»¶ï¼ˆä¿ç•™2ä»¶åº«å­˜ï¼‰
                   base_transferable = store['SaSa Net Stock'] - 2
                   max_transferable = int(total_available * 0.9)  # 90%é™åˆ¶
                   actual_transfer = min(base_transferable, max_transferable, store['SaSa Net Stock'])

                   if actual_transfer > 0:
                       transfer_out_candidates.append({
                           'Article': article,
                           'OM': om,
                           'Site': store['Site'],
                           'Transfer Type': 'RFç‰¹å¼·è½‰å‡º',
                           'Available Stock': store['SaSa Net Stock'],
                           'Transfer Qty': actual_transfer,
                           'Effective Sales': store['Effective Sales'],
                           'Original Stock': store['SaSa Net Stock'],
                           'Safety Stock': store['Safety Stock'],
                           'MOQ': store['MOQ'],
                           'Pending Received': store['Pending Received'],
                           'Article Total Demand': article_total_demand
                       })

   return pd.DataFrame(transfer_out_candidates)

def identify_transfer_in_candidates(df: pd.DataFrame) -> pd.DataFrame:
   """
   è­˜åˆ¥è½‰å…¥å€™é¸ï¼ˆæœ‰ç›®æ¨™éœ€æ±‚çš„åº—é‹ªï¼‰

   Args:
       df: è™•ç†å¾Œçš„è³‡æ–™æ¡†

   Returns:
       pd.DataFrame: è½‰å…¥å€™é¸æ¸…å–®
   """
   transfer_in_candidates = []

   # ç¯©é¸æœ‰ç›®æ¨™éœ€æ±‚çš„åº—é‹ª
   target_stores = df[df['Target'] > 0]

   for _, store in target_stores.iterrows():
       transfer_in_candidates.append({
           'Article': store['Article'],
           'OM': store['OM'],
           'Site': store['Site'],
           'Transfer Type': 'æŒ‡å®šåº—é‹ªè£œè²¨',
           'Required Qty': store['Target'],
           'Effective Sales': calculate_effective_sales(store),
           'Current Stock': store['SaSa Net Stock'],
           'Safety Stock': store['Safety Stock'],
           'MOQ': store['MOQ']
       })

   return pd.DataFrame(transfer_in_candidates)

# ============================================================================
# éŒ¯èª¤è™•ç†å‡½æ•¸
# ============================================================================

def handle_no_transfer_candidates(transfer_out_df: pd.DataFrame,
                               transfer_in_df: pd.DataFrame,
                               mode: str) -> dict:
   """
   è™•ç†æ²’æœ‰æ‰¾åˆ°åˆæ ¼è½‰è²¨å€™é¸çš„æƒ…æ³

   Args:
       transfer_out_df: è½‰å‡ºå€™é¸è³‡æ–™æ¡†
       transfer_in_df: è½‰å…¥å€™é¸è³‡æ–™æ¡†
       mode: è½‰è²¨æ¨¡å¼

   Returns:
       dict: éŒ¯èª¤è³‡è¨Šå’Œå»ºè­°
   """
   # åˆ†ææƒ…æ³
   no_out_candidates = transfer_out_df.empty
   no_in_candidates = transfer_in_df.empty

   # å‰µå»ºè¨ºæ–·è³‡è¨Š
   diagnostic_info = {
       'mode': mode,
       'transfer_out_count': len(transfer_out_df),
       'transfer_in_count': len(transfer_in_df),
       'reason': 'unknown'
   }

   if no_out_candidates and no_in_candidates:
       diagnostic_info['reason'] = 'no_eligible_candidates'
       message = "æ²’æœ‰æ‰¾åˆ°ç¬¦åˆè½‰å‡ºæˆ–è½‰å…¥æ¢ä»¶çš„å€™é¸å•†åº—ã€‚è«‹æª¢æŸ¥è³‡æ–™æ˜¯å¦åŒ…å«ï¼š\n" \
                "â€¢ NDé¡å‹ä¸”åº«å­˜å¤§æ–¼0çš„ç”¢å“\n" \
                "â€¢ å…·æœ‰ç›®æ¨™éœ€æ±‚é‡çš„ç”¢å“"
   elif no_out_candidates:
       diagnostic_info['reason'] = 'no_transfer_out_candidates'
       message = "æ²’æœ‰æ‰¾åˆ°ç¬¦åˆè½‰å‡ºæ¢ä»¶çš„å€™é¸å•†åº—ã€‚è«‹æª¢æŸ¥ï¼š\n" \
                "â€¢ æ˜¯å¦æœ‰NDé¡å‹ç”¢å“ä¸”åº«å­˜å¤§æ–¼0\n" \
                "â€¢ RFé¡å‹ç”¢å“æ˜¯å¦æ»¿è¶³è½‰å‡ºæ¢ä»¶ï¼ˆä¾æ‰€é¸æ¨¡å¼è€Œå®šï¼‰"
   elif no_in_candidates:
       diagnostic_info['reason'] = 'no_transfer_in_candidates'
       message = "æ²’æœ‰æ‰¾åˆ°ç¬¦åˆè½‰å…¥æ¢ä»¶çš„å€™é¸å•†åº—ã€‚è«‹æª¢æŸ¥ï¼š\n" \
                "â€¢ æ˜¯å¦æœ‰ç”¢å“è¨­ç½®äº†ç›®æ¨™éœ€æ±‚é‡ï¼ˆTarget > 0ï¼‰"
   else:
       # æª¢æŸ¥è½‰å‡ºå’Œè½‰å…¥å€™é¸çš„ç”¢å“æ˜¯å¦æœ‰é‡ç–Š
       out_articles = set(transfer_out_df['Article'].unique())
       in_articles = set(transfer_in_df['Article'].unique())
       common_articles = out_articles.intersection(in_articles)

       if not common_articles:
           diagnostic_info['reason'] = 'no_common_articles'
           message = "æ²’æœ‰æ‰¾åˆ°å¯ä»¥åŒ¹é…çš„ç”¢å“ã€‚è½‰å‡ºå€™é¸å’Œè½‰å…¥å€™é¸çš„ç”¢å“æ²’æœ‰é‡ç–Šã€‚"
       else:
           diagnostic_info['reason'] = 'om_constraint_violation'
           message = "æ²’æœ‰æ‰¾åˆ°ç¬¦åˆOMç´„æŸçš„è½‰è²¨æ©Ÿæœƒã€‚ç³»çµ±è¦æ±‚è½‰å‡ºå’Œè½‰å…¥å¿…é ˆåœ¨åŒä¸€OMå–®ä½å…§ã€‚"

   # å‰µå»ºä½¿ç”¨è€…å‹å¥½çš„éŒ¯èª¤å›æ‡‰
   error_response = {
       'success': False,
       'message': message,
       'diagnostic': diagnostic_info,
       'suggestions': [
           "æª¢æŸ¥Excelæª”æ¡ˆæ˜¯å¦åŒ…å«æ‰€æœ‰å¿…è¦æ¬„ä½",
           "ç¢ºèªæ˜¯å¦æœ‰NDé¡å‹ç”¢å“ä¸”åº«å­˜å¤§æ–¼0",
           "ç¢ºèªæ˜¯å¦æœ‰ç”¢å“è¨­ç½®äº†ç›®æ¨™éœ€æ±‚é‡",
           "æª¢æŸ¥è½‰å‡ºå’Œè½‰å…¥ç”¢å“æ˜¯å¦å±¬æ–¼åŒä¸€OMå–®ä½",
           "é©—è­‰è³‡æ–™æ ¼å¼æ˜¯å¦æ­£ç¢ºï¼ˆæ•¸å€¼æ¬„ä½æ‡‰ç‚ºæ•¸å­—ï¼‰"
       ]
   }

   return error_response

# ============================================================================
# è½‰è²¨åŒ¹é…æ¼”ç®—æ³•
# ============================================================================

def match_transfers(transfer_out_df: pd.DataFrame,
                  transfer_in_df: pd.DataFrame,
                  original_df: pd.DataFrame) -> pd.DataFrame:
   """
   åŒ¹é…è½‰å‡ºå’Œè½‰å…¥å€™é¸ï¼Œç”Ÿæˆè½‰è²¨å»ºè­°

   é—œéµç´„æŸï¼šç¸½è½‰å‡ºæ•¸é‡ä¸èƒ½è¶…éç¸½éœ€æ±‚æ•¸é‡

   Args:
       transfer_out_df: è½‰å‡ºå€™é¸è³‡æ–™æ¡†
       transfer_in_df: è½‰å…¥å€™é¸è³‡æ–™æ¡†
       original_df: åŸå§‹è³‡æ–™æ¡†

   Returns:
       pd.DataFrame: è½‰è²¨å»ºè­°æ¸…å–®
   """
   transfer_suggestions = []

   # æª¢æŸ¥è³‡æ–™æ¡†æ˜¯å¦ç‚ºç©º
   if transfer_out_df.empty or transfer_in_df.empty:
       return pd.DataFrame(transfer_suggestions)

   # å‰µå»ºè½‰å…¥è³‡æ–™å‰¯æœ¬é¿å…ä¿®æ”¹åŸè³‡æ–™
   transfer_in_df_copy = transfer_in_df.copy()

   # æŒ‰ç”¢å“åˆ†çµ„ä»¥æ‡‰ç”¨ç´„æŸæ¢ä»¶
   out_grouped = transfer_out_df.groupby(['Article'])
   in_grouped = transfer_in_df_copy.groupby(['Article'])

   for article, out_group in out_grouped:
       if article in in_grouped.groups:
           in_group = in_grouped.get_group(article)

           # è¨ˆç®—æ­¤ç”¢å“åœ¨æ‰€æœ‰OMä¸­çš„ç¸½éœ€æ±‚
           total_demand = in_group['Required Qty'].sum()

           # ç²å–æ­¤ç”¢å“çš„æ‰€æœ‰è½‰å‡ºå€™é¸ï¼ˆè·¨æ‰€æœ‰OMï¼‰
           out_group_sorted = out_group.sort_values(['OM', 'Transfer Type', 'Effective Sales'],
                                                  ascending=[True, True, True])

           # è½‰å…¥å€™é¸æŒ‰OMå’Œæœ‰æ•ˆéŠ·é‡æ’åºï¼ˆéŠ·é‡é«˜çš„å„ªå…ˆï¼‰
           in_group_sorted = in_group.sort_values(['OM', 'Effective Sales'], ascending=[True, False])

           # è¿½è¹¤æ­¤ç”¢å“åœ¨æ‰€æœ‰OMä¸­çš„ç¸½è½‰å‡ºæ•¸é‡
           total_transferred = 0

           # åŸ·è¡Œè½‰è²¨åŒ¹é…
           for _, out_store in out_group_sorted.iterrows():
               remaining_qty = out_store['Transfer Qty']

               for idx, in_store in in_group_sorted.iterrows():
                   if remaining_qty <= 0:
                       break

                   # é¿å…åŒä¸€åº—é‹ªè‡ªæˆ‘è½‰è²¨
                   if out_store['Site'] == in_store['Site']:
                       continue

                   # è¨ˆç®—æ½›åœ¨è½‰ç§»æ•¸é‡
                   potential_transfer_qty = min(remaining_qty, in_store['Required Qty'])

                   # æ‡‰ç”¨å…¨åŸŸéœ€æ±‚ç´„æŸï¼ˆé‡å°æ­¤ç”¢å“ï¼‰
                   if total_transferred + potential_transfer_qty > total_demand:
                       potential_transfer_qty = max(0, total_demand - total_transferred)

                   if potential_transfer_qty > 0:
                       # å¾åŸè³‡æ–™ç²å–ç”¢å“æè¿°
                       product_desc = original_df[original_df['Article'] == article]['Article Description'].iloc[0]

                       transfer_suggestions.append({
                           'Article': article,
                           'Product Desc': product_desc,
                           'OM': out_store['OM'],
                           'Transfer Site': out_store['Site'],
                           'Transfer Qty': potential_transfer_qty,
                           'Transfer Site Original Stock': out_store['Original Stock'],
                           'Transfer Site After Transfer Stock': out_store['Original Stock'] - potential_transfer_qty,
                           'Transfer Site Safety Stock': out_store['Safety Stock'],
                           'Transfer Site MOQ': out_store['MOQ'],
                           'Receive Site': in_store['Site'],
                           'Receive Site Target Qty': in_store['Required Qty'],
                           'Transfer Type': out_store['Transfer Type'],
                           'Notes': f"å¾{out_store['Site']}è½‰ç§»è‡³{in_store['Site']}"
                       })

                       # æ›´æ–°è¿½è¹¤è®Šæ•¸
                       remaining_qty -= potential_transfer_qty
                       total_transferred += potential_transfer_qty

                       # æ›´æ–°æ¥æ”¶åº—é‹ªçš„å‰©é¤˜éœ€æ±‚é‡ï¼ˆåœ¨å‰¯æœ¬ä¸­ï¼‰
                       transfer_in_df_copy.loc[idx, 'Required Qty'] -= potential_transfer_qty

                       # æ›´æ–°æ’åºå¾Œçš„è½‰å…¥ç¾¤çµ„ä»¥ä¾›ä¸‹æ¬¡è¿­ä»£ä½¿ç”¨
                       in_group_sorted.loc[idx, 'Required Qty'] -= potential_transfer_qty

   return pd.DataFrame(transfer_suggestions)

# ============================================================================
# çµ±è¨ˆåˆ†æå‡½æ•¸
# ============================================================================

def calculate_statistics(transfer_suggestions_df: pd.DataFrame, mode: str) -> dict:
   """
   è¨ˆç®—å®Œæ•´çš„çµ±è¨ˆåˆ†æï¼ŒåŒ…æ‹¬ç´„æŸé©—è­‰

   Args:
       transfer_suggestions_df: è½‰è²¨å»ºè­°è³‡æ–™æ¡†
       mode: è½‰è²¨æ¨¡å¼

   Returns:
       dict: çµ±è¨ˆçµæœ
   """
   if transfer_suggestions_df.empty:
       return {
           'total_transfer_qty': 0,
           'total_transfer_lines': 0,
           'unique_articles': 0,
           'unique_oms': 0,
           'article_stats': pd.DataFrame(),
           'om_stats': pd.DataFrame(),
           'transfer_type_stats': pd.DataFrame(),
           'receive_stats': pd.DataFrame(),
           'constraint_violations': 0,
           'violation_details': []
       }

   # åŸºæœ¬KPIæŒ‡æ¨™
   total_transfer_qty = transfer_suggestions_df['Transfer Qty'].sum()
   total_transfer_lines = len(transfer_suggestions_df)
   unique_articles = transfer_suggestions_df['Article'].nunique()
   unique_oms = transfer_suggestions_df['OM'].nunique()

   # è¨ˆç®—æ¯å€‹ç”¢å“çš„ç¸½éœ€æ±‚å’Œç¸½è½‰å‡ºï¼ˆç”¨æ–¼ç´„æŸé©—è­‰ï¼‰
   total_demand_by_article = transfer_suggestions_df.groupby('Article')['Receive Site Target Qty'].first()
   total_transfer_by_article = transfer_suggestions_df.groupby('Article')['Transfer Qty'].sum()

   # æª¢æŸ¥ç´„æŸé•è¦
   constraint_violations = 0
   violation_details = []

   for article in total_demand_by_article.index:
       demand = total_demand_by_article[article]
       transfer = total_transfer_by_article.get(article, 0)
       if transfer > demand:
           constraint_violations += 1
           violation_details.append({
               'Article': article,
               'Total Demand': demand,
               'Total Transfer': transfer,
               'Violation': transfer - demand
           })

   # æŒ‰ç”¢å“çµ±è¨ˆ
   article_stats = transfer_suggestions_df.groupby('Article').agg({
       'Receive Site Target Qty': 'first',  # ç¸½éœ€æ±‚ä»¶æ•¸
       'Transfer Qty': 'sum',  # ç¸½èª¿è²¨ä»¶æ•¸
       'OM': 'nunique'  # æ¶‰åŠOMæ•¸é‡
   }).round(2)
   article_stats.columns = ['ç¸½éœ€æ±‚ä»¶æ•¸', 'ç¸½èª¿è²¨ä»¶æ•¸', 'æ¶‰åŠOMæ•¸é‡']
   article_stats['è½‰è²¨è¡Œæ•¸'] = transfer_suggestions_df.groupby('Article').size()
   article_stats['éœ€æ±‚æ»¿è¶³ç‡'] = (article_stats['ç¸½èª¿è²¨ä»¶æ•¸'] / article_stats['ç¸½éœ€æ±‚ä»¶æ•¸'] * 100).round(2)
   article_stats['ç´„æŸé•è¦'] = [(total_transfer_by_article.get(article, 0) > article_stats.loc[article, 'ç¸½éœ€æ±‚ä»¶æ•¸']) for article in article_stats.index]

   # æŒ‰OMçµ±è¨ˆ
   om_stats = transfer_suggestions_df.groupby('OM').agg({
       'Receive Site Target Qty': 'first',  # ç¸½éœ€æ±‚ä»¶æ•¸
       'Transfer Qty': 'sum',  # ç¸½èª¿è²¨ä»¶æ•¸
       'Article': 'nunique'  # æ¶‰åŠç”¢å“æ•¸é‡
   }).round(2)
   om_stats.columns = ['ç¸½éœ€æ±‚ä»¶æ•¸', 'ç¸½èª¿è²¨ä»¶æ•¸', 'æ¶‰åŠç”¢å“æ•¸é‡']
   om_stats['è½‰è²¨è¡Œæ•¸'] = transfer_suggestions_df.groupby('OM').size()

   # è½‰å‡ºé¡å‹åˆ†ä½ˆ
   transfer_type_stats = transfer_suggestions_df.groupby('Transfer Type').agg({
       'Transfer Qty': ['sum', 'count']
   }).round(2)
   transfer_type_stats.columns = ['ç¸½ä»¶æ•¸', 'æ¶‰åŠè¡Œæ•¸']

   # æ¥æ”¶çµ±è¨ˆ
   receive_stats = transfer_suggestions_df.groupby('Receive Site').agg({
       'Transfer Qty': 'sum',
       'Receive Site Target Qty': 'first'
   }).round(2)
   receive_stats.columns = ['å¯¦éš›æ¥æ”¶æ•¸é‡', 'ç›®æ¨™éœ€æ±‚æ•¸é‡']
   receive_stats['éœ€æ±‚æ»¿è¶³ç‡'] = (receive_stats['å¯¦éš›æ¥æ”¶æ•¸é‡'] / receive_stats['ç›®æ¨™éœ€æ±‚æ•¸é‡'] * 100).round(2)

   return {
       'total_transfer_qty': total_transfer_qty,
       'total_transfer_lines': total_transfer_lines,
       'unique_articles': unique_articles,
       'unique_oms': unique_oms,
       'article_stats': article_stats,
       'om_stats': om_stats,
       'transfer_type_stats': transfer_type_stats,
       'receive_stats': receive_stats,
       'constraint_violations': constraint_violations,
       'violation_details': violation_details
   }

# ============================================================================
# è¦–è¦ºåŒ–å‡½æ•¸
# ============================================================================

def create_visualization(stats: dict, transfer_suggestions_df: pd.DataFrame, mode: str):
   """
   æ ¹æ“šæ¨¡å¼å‰µå»ºmatplotlibè¦–è¦ºåŒ–åœ–è¡¨

   Args:
       stats: çµ±è¨ˆè³‡æ–™
       transfer_suggestions_df: è½‰è²¨å»ºè­°è³‡æ–™æ¡†
       mode: è½‰è²¨æ¨¡å¼

   Returns:
       matplotlibåœ–è¡¨ç‰©ä»¶æˆ–None
   """
   if transfer_suggestions_df.empty:
       return None

   fig, ax = plt.subplots(figsize=(14, 8))

   # æº–å‚™è½‰å‡ºè³‡æ–™ï¼ˆæŒ‰OMå’Œè½‰è²¨é¡å‹ï¼‰
   transfer_out_by_om_type = transfer_suggestions_df.groupby(['OM', 'Transfer Type'])['Transfer Qty'].sum().unstack(fill_value=0)

   # æº–å‚™æ¥æ”¶è³‡æ–™ï¼ˆæŒ‰OMï¼‰
   receive_data = transfer_suggestions_df.groupby('Receive Site')['Transfer Qty'].sum()
   receive_by_om = transfer_suggestions_df.drop_duplicates('Receive Site').set_index('Receive Site')['OM']
   receive_by_om = receive_by_om[receive_data.index]
   receive_by_om_grouped = receive_by_om.groupby(receive_by_om).sum().rename('å¯¦éš›æ¥æ”¶æ•¸é‡')

   # æº–å‚™ç›®æ¨™è³‡æ–™ï¼ˆæŒ‰OMï¼‰
   target_by_om = transfer_suggestions_df.drop_duplicates('Receive Site').groupby('OM')['Receive Site Target Qty'].sum().rename('éœ€æ±‚æ¥æ”¶æ•¸é‡')

   # åˆä½µæ‰€æœ‰è³‡æ–™
   combined_data = transfer_out_by_om_type.join(receive_by_om_grouped).join(target_by_om).fillna(0)

   # æ ¹æ“šæ¨¡å¼å®šç¾©é æœŸçš„æ¬„ä½
   if mode == 'conservative':
       # æ¨¡å¼Aï¼š4æ¢å½¢è¨­è¨ˆ
       expected_columns = ['NDè½‰å‡º', 'RFéå‰©è½‰å‡º', 'éœ€æ±‚æ¥æ”¶æ•¸é‡', 'å¯¦éš›æ¥æ”¶æ•¸é‡']
   elif mode == 'enhanced':
       # æ¨¡å¼Bï¼š5æ¢å½¢è¨­è¨ˆ
       expected_columns = ['NDè½‰å‡º', 'RFéå‰©è½‰å‡º', 'RFåŠ å¼·è½‰å‡º', 'éœ€æ±‚æ¥æ”¶æ•¸é‡', 'å¯¦éš›æ¥æ”¶æ•¸é‡']
   else:  # special mode
       # æ¨¡å¼Cï¼š5æ¢å½¢è¨­è¨ˆ
       expected_columns = ['NDè½‰å‡º', 'RFéå‰©è½‰å‡º', 'RFç‰¹å¼·è½‰å‡º', 'éœ€æ±‚æ¥æ”¶æ•¸é‡', 'å¯¦éš›æ¥æ”¶æ•¸é‡']

   # ç¯©é¸ä¸¦é‡æ–°æ’åºæ¬„ä½
   available_columns = [col for col in expected_columns if col in combined_data.columns]
   combined_data = combined_data[available_columns]

   # å‰µå»ºé•·æ¢åœ–
   combined_data.plot(kind='bar', ax=ax, width=0.8)

   ax.set_title('Transfer Receive Analysis', fontsize=16, fontweight='bold')
   ax.set_xlabel('OMå–®ä½', fontsize=12)
   ax.set_ylabel('èª¿è²¨æ•¸é‡', fontsize=12)
   ax.legend(title='è½‰è²¨é¡å‹', bbox_to_anchor=(1.05, 1), loc='upper left')
   ax.grid(axis='y', alpha=0.3)

   plt.xticks(rotation=45)
   plt.tight_layout()

   return fig

# ============================================================================
# ExcelåŒ¯å‡ºå‡½æ•¸
# ============================================================================

def export_to_excel(transfer_suggestions_df: pd.DataFrame, stats: dict) -> io.BytesIO:
   """
   åŒ¯å‡ºçµæœåˆ°Excelæª”æ¡ˆï¼Œæ ¼å¼å®Œå…¨ç¬¦åˆéœ€æ±‚

   Args:
       transfer_suggestions_df: è½‰è²¨å»ºè­°è³‡æ–™æ¡†
       stats: çµ±è¨ˆè³‡æ–™

   Returns:
       io.BytesIO: Excelæª”æ¡ˆå…§å®¹
   """
   output = io.BytesIO()

   with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
       # å·¥ä½œè¡¨1ï¼šè½‰è²¨å»ºè­°ï¼ˆç‰¹å®šæ¬„ä½é †åºï¼‰
       required_columns = [
           'Article', 'Product Desc', 'OM', 'Transfer Site', 'Transfer Qty',
           'Transfer Site Original Stock', 'Transfer Site After Transfer Stock',
           'Transfer Site Safety Stock', 'Transfer Site MOQ', 'Receive Site',
           'Receive Site Target Qty', 'Notes'
       ]

       # ç¯©é¸å­˜åœ¨çš„æ¬„ä½
       available_columns = [col for col in required_columns if col in transfer_suggestions_df.columns]
       export_df = transfer_suggestions_df[available_columns].copy()

       # é‡æ–°å‘½åæ¬„ä½ç‚ºè‹±æ–‡ï¼ˆç³»çµ±ç›¸å®¹æ€§ï¼‰
       column_rename_map = {
           'Article': 'Article',
           'Product Desc': 'Product Description',
           'OM': 'OM',
           'Transfer Site': 'Transfer Site',
           'Transfer Qty': 'Transfer Qty',
           'Transfer Site Original Stock': 'Transfer Site Original Stock',
           'Transfer Site After Transfer Stock': 'Transfer Site After Transfer Stock',
           'Transfer Site Safety Stock': 'Transfer Site Safety Stock',
           'Transfer Site MOQ': 'Transfer Site MOQ',
           'Receive Site': 'Receive Site',
           'Receive Site Target Qty': 'Receive Site Target Qty',
           'Notes': 'Notes'
       }

       export_df = export_df.rename(columns=column_rename_map)
       export_df.to_excel(writer, sheet_name='èª¿è²¨å»ºè­°', index=False)

       # å·¥ä½œè¡¨2ï¼šçµ±è¨ˆæ‘˜è¦ï¼ˆé©ç•¶é–“è·ï¼‰
       workbook = writer.book
       worksheet = workbook.add_worksheet('çµ±è¨ˆæ‘˜è¦')

       # KPIæ¦‚è¦½
       row = 0
       worksheet.write(row, 0, 'KPI Overview')
       worksheet.write(row, 1, 'ç¸½è½‰è²¨å»ºè­°æ•¸é‡')
       worksheet.write(row, 2, stats['total_transfer_qty'])
       row += 1
       worksheet.write(row, 1, 'ç¸½è½‰è²¨ä»¶æ•¸')
       worksheet.write(row, 2, stats['total_transfer_lines'])
       row += 1
       worksheet.write(row, 1, 'æ¶‰åŠç”¢å“æ•¸é‡')
       worksheet.write(row, 2, stats['unique_articles'])
       row += 1
       worksheet.write(row, 1, 'æ¶‰åŠOMæ•¸é‡')
       worksheet.write(row, 2, stats['unique_oms'])
       row += 1

       # ç•™3è¡Œç©ºç™½
       row += 3

       # æŒ‰ç”¢å“çµ±è¨ˆ
       if not stats['article_stats'].empty:
           worksheet.write(row, 0, 'Statistics by Article')
           row += 1
           # å¯«å…¥æ¨™é¡Œ
           headers = ['Article', 'ç¸½éœ€æ±‚ä»¶æ•¸', 'ç¸½èª¿è²¨ä»¶æ•¸', 'æ¶‰åŠOMæ•¸é‡', 'è½‰è²¨è¡Œæ•¸', 'éœ€æ±‚æ»¿è¶³ç‡', 'ç´„æŸé•è¦']
           for col_num, header in enumerate(headers):
               worksheet.write(row, col_num, header)
           row += 1

           # å¯«å…¥è³‡æ–™
           for article in stats['article_stats'].index:
               base_col = 0
               worksheet.write(row, base_col, article)
               worksheet.write(row, base_col + 1, stats['article_stats'].loc[article, 'ç¸½éœ€æ±‚ä»¶æ•¸'])
               worksheet.write(row, base_col + 2, stats['article_stats'].loc[article, 'ç¸½èª¿è²¨ä»¶æ•¸'])
               worksheet.write(row, base_col + 3, stats['article_stats'].loc[article, 'æ¶‰åŠOMæ•¸é‡'])
               worksheet.write(row, base_col + 4, stats['article_stats'].loc[article, 'è½‰è²¨è¡Œæ•¸'])
               worksheet.write(row, base_col + 5, stats['article_stats'].loc[article, 'éœ€æ±‚æ»¿è¶³ç‡'])
               worksheet.write(row, base_col + 6, 'æ˜¯' if stats['article_stats'].loc[article, 'ç´„æŸé•è¦'] else 'å¦')
               row += 1

           row += 3  # ç•™3è¡Œç©ºç™½

       # æŒ‰OMçµ±è¨ˆ
       if not stats['om_stats'].empty:
           worksheet.write(row, 0, 'Statistics by OM')
           row += 1
           # å¯«å…¥æ¨™é¡Œ
           headers = ['OM', 'ç¸½éœ€æ±‚ä»¶æ•¸', 'ç¸½èª¿è²¨ä»¶æ•¸', 'æ¶‰åŠç”¢å“æ•¸é‡', 'è½‰è²¨è¡Œæ•¸']
           for col_num, header in enumerate(headers):
               worksheet.write(row, col_num, header)
           row += 1

           # å¯«å…¥è³‡æ–™
           for om in stats['om_stats'].index:
               base_col = 0
               worksheet.write(row, base_col, om)
               worksheet.write(row, base_col + 1, stats['om_stats'].loc[om, 'ç¸½éœ€æ±‚ä»¶æ•¸'])
               worksheet.write(row, base_col + 2, stats['om_stats'].loc[om, 'ç¸½èª¿è²¨ä»¶æ•¸'])
               worksheet.write(row, base_col + 3, stats['om_stats'].loc[om, 'æ¶‰åŠç”¢å“æ•¸é‡'])
               worksheet.write(row, base_col + 4, stats['om_stats'].loc[om, 'è½‰è²¨è¡Œæ•¸'])
               row += 1

           row += 3  # ç•™3è¡Œç©ºç™½

       # è½‰å‡ºé¡å‹åˆ†ä½ˆ
       if not stats['transfer_type_stats'].empty:
           worksheet.write(row, 0, 'Transfer Type Distribution')
           row += 1
           # å¯«å…¥æ¨™é¡Œ
           headers = ['Transfer Type', 'ç¸½ä»¶æ•¸', 'æ¶‰åŠè¡Œæ•¸']
           for col_num, header in enumerate(headers):
               worksheet.write(row, col_num, header)
           row += 1

           # å¯«å…¥è³‡æ–™
           for transfer_type in stats['transfer_type_stats'].index:
               base_col = 0
               worksheet.write(row, base_col, transfer_type)
               worksheet.write(row, base_col + 1, stats['transfer_type_stats'].loc[transfer_type, 'ç¸½ä»¶æ•¸'])
               worksheet.write(row, base_col + 2, stats['transfer_type_stats'].loc[transfer_type, 'æ¶‰åŠè¡Œæ•¸'])
               row += 1

           row += 3  # ç•™3è¡Œç©ºç™½

       # æ¥æ”¶é¡å‹åˆ†ä½ˆ
       if not stats['receive_stats'].empty:
           worksheet.write(row, 0, 'Receive Type Distribution')
           row += 1
           # å¯«å…¥æ¨™é¡Œ
           headers = ['Receive Site', 'å¯¦éš›æ¥æ”¶æ•¸é‡', 'ç›®æ¨™éœ€æ±‚æ•¸é‡', 'éœ€æ±‚æ»¿è¶³ç‡']
           for col_num, header in enumerate(headers):
               worksheet.write(row, col_num, header)
           row += 1

           # å¯«å…¥è³‡æ–™
           for receive_site in stats['receive_stats'].index:
               base_col = 0
               worksheet.write(row, base_col, receive_site)
               worksheet.write(row, base_col + 1, stats['receive_stats'].loc[receive_site, 'å¯¦éš›æ¥æ”¶æ•¸é‡'])
               worksheet.write(row, base_col + 2, stats['receive_stats'].loc[receive_site, 'ç›®æ¨™éœ€æ±‚æ•¸é‡'])
               worksheet.write(row, base_col + 3, stats['receive_stats'].loc[receive_site, 'éœ€æ±‚æ»¿è¶³ç‡'])
               row += 1

   output.seek(0)
   return output

# ============================================================================
# ä¸»æ‡‰ç”¨ç¨‹å¼
# ============================================================================

def main():
   """
   Streamlitä¸»æ‡‰ç”¨ç¨‹å¼
   """
   # é é¢æ¨™é ­
   st.title("ğŸ“¦ èª¿è²¨å»ºè­°ç”Ÿæˆç³»çµ±")
   st.markdown("---")

   # å´é‚Šæ¬„
   st.sidebar.header("ç³»çµ±è³‡è¨Š")
   st.sidebar.info("""
**ç‰ˆæœ¬ï¼šv1.0**
**é–‹ç™¼è€…:Ricky**

**æ ¸å¿ƒåŠŸèƒ½ï¼š**
- âœ… ND/RFé¡å‹æ™ºæ…§è­˜åˆ¥
- âœ… å„ªå…ˆé †åºè½‰è²¨
- âœ… çµ±è¨ˆåˆ†æå’Œåœ–è¡¨
- âœ… Excelæ ¼å¼åŒ¯å‡º
""")

   # æª”æ¡ˆä¸Šå‚³å€å¡Š
   st.header("1. è³‡æ–™ä¸Šå‚³")
   uploaded_file = st.file_uploader(
       "è«‹ä¸Šå‚³Excelæª”æ¡ˆ (.xlsx, .xls)",
       type=['xlsx', 'xls'],
       help="æª”æ¡ˆå¿…é ˆåŒ…å«æ‰€æœ‰å¿…è¦çš„æ¬„ä½ï¼šArticle, Article Description, RP Type, Site, OM, MOQ, SaSa Net Stock, Target, Pending Received, Safety Stock, Last Month Sold Qty, MTD Sold Qty"
   )

   if uploaded_file is not None:
       try:
           # è®€å–ä¸Šå‚³çš„æª”æ¡ˆ
           df = pd.read_excel(uploaded_file)

           # é©—è­‰æª”æ¡ˆçµæ§‹
           is_valid, message = validate_file_structure(df)

           if not is_valid:
               st.error(f"âŒ {message}")
               return

           # é è™•ç†è³‡æ–™
           with st.spinner("æ­£åœ¨è™•ç†è³‡æ–™..."):
               df = preprocess_data(df)

           st.success("âœ… æª”æ¡ˆä¸Šå‚³ä¸¦è™•ç†æˆåŠŸï¼")

           # è³‡æ–™é è¦½å€å¡Š
           st.header("2. è³‡æ–™é è¦½")

           col1, col2, col3 = st.columns(3)
           with col1:
               st.metric("ç¸½è¨˜éŒ„æ•¸", len(df))
           with col2:
               st.metric("ç”¢å“æ•¸é‡", df['Article'].nunique())
           with col3:
               st.metric("åº—é‹ªæ•¸é‡", df['Site'].nunique())

           # é¡¯ç¤ºæ¨£æœ¬è³‡æ–™
           st.subheader("è³‡æ–™æ¨£æœ¬")
           st.dataframe(df.head(10))

           # è½‰è²¨æ¨¡å¼é¸æ“‡
           st.header("3. è½‰è²¨æ¨¡å¼é¸æ“‡")
           mode = st.radio(
               "è«‹é¸æ“‡è½‰è²¨æ¨¡å¼ï¼š",
               options=["conservative", "enhanced", "special"],
               format_func=lambda x: "A: ä¿å®ˆè½‰è²¨" if x == "conservative" else ("B: åŠ å¼·è½‰è²¨" if x == "enhanced" else "C: ç‰¹å¼·è½‰è²¨"),
               help="ä¿å®ˆè½‰è²¨ï¼šRFé¡å‹è½‰å‡ºé™åˆ¶ç‚º50% | åŠ å¼·è½‰è²¨ï¼šRFé¡å‹è½‰å‡ºé™åˆ¶ç‚º80% | ç‰¹å¼·è½‰è²¨ï¼šRFé¡å‹è½‰å‡ºé™åˆ¶ç‚º90%ä¸¦ä¿ç•™2ä»¶åº«å­˜"
           )

           # åˆ†æåŸ·è¡Œå€å¡Š
           st.header("4. åˆ†æåŸ·è¡Œ")
           if st.button("ğŸš€ é–‹å§‹åˆ†æ", type="primary", use_container_width=True):
               with st.spinner("æ­£åœ¨ç”Ÿæˆè½‰è²¨å»ºè­°..."):
                   # è­˜åˆ¥è½‰è²¨å€™é¸
                   transfer_out_df = identify_transfer_out_candidates(df, mode)
                   transfer_in_df = identify_transfer_in_candidates(df)

                   # åŒ¹é…è½‰è²¨
                   transfer_suggestions_df = match_transfers(transfer_out_df, transfer_in_df, df)

                   # è¨ˆç®—çµ±è¨ˆ
                   stats = calculate_statistics(transfer_suggestions_df, mode)

               st.success("âœ… åˆ†æå®Œæˆï¼")

               # çµæœå±•ç¤ºå€å¡Š
               st.header("5. åˆ†æçµæœ")

               # æª¢æŸ¥ç´„æŸé•è¦
               if stats.get('constraint_violations', 0) > 0:
                   st.error(f"âš ï¸ ç™¼ç¾ {stats['constraint_violations']} å€‹ç´„æŸé•è¦ï¼šç¸½è½‰å‡ºæ•¸é‡è¶…éç¸½éœ€æ±‚æ•¸é‡")

                   # åœ¨å¯å±•é–‹å€å¡Šé¡¯ç¤ºé•è¦è©³æƒ…
                   with st.expander("ç´„æŸé•è¦è©³æƒ…"):
                       for violation in stats.get('violation_details', []):
                           st.write(f"**ç”¢å“ {violation['Article']}**:")
                           st.write(f"  - ç¸½éœ€æ±‚: {violation['Total Demand']}")
                           st.write(f"  - ç¸½è½‰å‡º: {violation['Total Transfer']}")
                           st.write(f"  - é•è¦æ•¸é‡: {violation['Violation']}")
               else:
                   # æ·»åŠ ç´„æŸåˆè¦æŒ‡ç¤ºå™¨
                   if stats.get('total_transfer_qty', 0) > 0:
                       st.success("âœ… æ‰€æœ‰è½‰è²¨å»ºè­°å‡ç¬¦åˆéœ€æ±‚ç´„æŸ")

               # KPIæŒ‡æ¨™
               col1, col2, col3, col4 = st.columns(4)
               with col1:
                   st.metric("ç¸½è½‰è²¨å»ºè­°æ•¸é‡", stats['total_transfer_qty'])
               with col2:
                   st.metric("ç¸½è½‰è²¨ä»¶æ•¸", stats['total_transfer_lines'])
               with col3:
                   st.metric("æ¶‰åŠç”¢å“æ•¸é‡", stats['unique_articles'])
               with col4:
                   st.metric("æ¶‰åŠOMæ•¸é‡", stats['unique_oms'])

               # è½‰è²¨å»ºè­°è¡¨æ ¼
               st.subheader("è½‰è²¨å»ºè­°æ˜ç´°")
               if not transfer_suggestions_df.empty:
                   st.dataframe(transfer_suggestions_df, use_container_width=True)
               else:
                   # ä½¿ç”¨éŒ¯èª¤è™•ç†å‡½æ•¸
                   error_info = handle_no_transfer_candidates(transfer_out_df, transfer_in_df, mode)

                   # é¡¯ç¤ºä½¿ç”¨è€…å‹å¥½çš„è¨Šæ¯
                   st.warning(f"âš ï¸ {error_info['message']}")

                   # åœ¨å¯å±•é–‹å€å¡Šé¡¯ç¤ºå»ºè­°
                   with st.expander("ç–‘é›£æ’è§£å»ºè­°"):
                       st.write("**å»ºè­°è§£æ±ºæ–¹æ¡ˆï¼š**")
                       for suggestion in error_info['suggestions']:
                           st.write(f"â€¢ {suggestion}")

               # çµ±è¨ˆåˆ†æè¡¨æ ¼
               st.subheader("çµ±è¨ˆåˆ†æ")

               if not transfer_suggestions_df.empty:
                   if not stats['article_stats'].empty:
                       st.write("**æŒ‰ç”¢å“çµ±è¨ˆ**")
                       st.dataframe(stats['article_stats'])

                   if not stats['om_stats'].empty:
                       st.write("**æŒ‰OMçµ±è¨ˆ**")
                       st.dataframe(stats['om_stats'])

                   if not stats['transfer_type_stats'].empty:
                       st.write("**è½‰å‡ºé¡å‹åˆ†ä½ˆ**")
                       st.dataframe(stats['transfer_type_stats'])

                   if not stats['receive_stats'].empty:
                       st.write("**æ¥æ”¶é¡å‹çµæœ**")
                       st.dataframe(stats['receive_stats'])

                   # æ•¸æ“šè¦–è¦ºåŒ–
                   st.subheader("æ•¸æ“šè¦–è¦ºåŒ–")
                   fig = create_visualization(stats, transfer_suggestions_df, mode)
                   if fig:
                       st.pyplot(fig)
                   else:
                       st.info("æ²’æœ‰è¶³å¤ çš„æ•¸æ“šç”Ÿæˆåœ–è¡¨")
               else:
                   st.info("ğŸ“Š æ²’æœ‰è½‰è²¨å»ºè­°è³‡æ–™ï¼Œç„¡æ³•ç”Ÿæˆçµ±è¨ˆåˆ†æå’Œåœ–è¡¨")

               # åŒ¯å‡ºå€å¡Š
               st.header("6. åŒ¯å‡ºåŠŸèƒ½")

               if not transfer_suggestions_df.empty:
                   # ç”ŸæˆExcelæª”æ¡ˆ
                   excel_data = export_to_excel(transfer_suggestions_df, stats)

                   # å‰µå»ºä¸‹è¼‰æŒ‰éˆ•
                   current_date = datetime.now().strftime("%Y%m%d")
                   filename = f"å¼·åˆ¶è½‰è²¨å»ºè­°_{current_date}.xlsx"

                   st.download_button(
                       label="ğŸ“¥ ä¸‹è¼‰Excelå ±å‘Š",
                       data=excel_data,
                       file_name=filename,
                       mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                   )
               else:
                   st.info("ğŸ“‹ æ²’æœ‰è½‰è²¨å»ºè­°è³‡æ–™ï¼Œç„¡æ³•ç”¢ç”ŸExcelå ±å‘Š")

       except Exception as e:
           st.error(f"âŒ è™•ç†æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}")
           st.error("è«‹æª¢æŸ¥æª”æ¡ˆæ ¼å¼å’Œå…§å®¹æ˜¯å¦ç¬¦åˆè¦æ±‚")

if __name__ == "__main__":
   main()